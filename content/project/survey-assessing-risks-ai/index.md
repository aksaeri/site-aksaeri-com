---
title: Survey Assessing Risks from AI (SARA)
date: 2024-04-11-16T07:05:11.172Z
summary: |-
  With Michael Noetel at The University of Queensland, I conducted a representative survey of ~1,000 Australian adults in Feb 2024 to understand public perceptions of AI risks and support for AI governance actions in Australia. 
  
  We found that: 
  
  - Australians are most concerned about AI risks where AI acts unsafely (e.g., acting in conflict with human values, failure of critical infrastructure), is misused (e.g., cyber attacks, biological weapons), or displaces the jobs of humans; they are least concerned about AI-assisted surveillance, or bias and discrimination in AI decision-making.
  - Australians judge “preventing dangerous and catastrophic outcomes from AI” the #1 priority for the Australian Government in AI; 9 in 10 Australians support creating a new regulatory body for AI.
  - The majority of Australians (8 in 10) support the statement that “mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war”.

  More on this project

  - [Website](https://aigovernance.org.au/survey/)
  - [Key results briefing](https://docs.google.com/document/d/1d0CRlBRLv3_a1fSye6cA6dzMjxtopjCcklc8irGPlDc/export?format=pdf&attachment=false)
  - [Technical report](https://aigovernance.org.au/survey/sara_technical_report)

  Contact me if you'd like a personal briefing on the findings.

draft: false
featured: false
external_link: 
image:
  filename: featured.jpg
  focal_point: Smart
  preview_only: false
---
